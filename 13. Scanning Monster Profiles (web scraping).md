‚úÖ Now we proceed to the **next major step: Scanning Monster Profiles (web scraping)** if no resumes are uploaded or no good candidates are found.

We‚Äôll simulate scanning from a job portal (like Monster) using **web scraping**. Since Monster may not allow API access, we‚Äôll demonstrate how to extract data using **Selenium**.

---

## ‚úÖ Step: Web Scraping Monster Profiles using Selenium (for educational/demo purposes)

> ‚ö†Ô∏è Use this only for learning or testing. Web scraping is subject to the website‚Äôs [Terms of Service](https://www.monster.com/terms-of-use).

---

### ‚úÖ Step 1: Install Selenium and WebDriver

```bash
pip install selenium
```

#### Download ChromeDriver

1. Go to: [https://sites.google.com/chromium.org/driver/](https://sites.google.com/chromium.org/driver/)
2. Download the version matching your Chrome browser.
3. Extract and place `chromedriver` in your project folder or system PATH.

---

### ‚úÖ Step 2: Create a New File for Web Scraping

üìÑ **File:** `core/monster_scraper.py`

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time

def fetch_monster_profiles(keyword, location='India'):
    options = Options()
    options.add_argument("--headless")  # Run in background
    driver = webdriver.Chrome(options=options)

    # Open Monster India Search Page
    search_url = f"https://www.monsterindia.com/srp/results?query={keyword}&locations={location}"
    driver.get(search_url)
    time.sleep(5)  # Wait for page to load

    candidates = []
    results = driver.find_elements(By.CLASS_NAME, "job-tittle")

    for job in results[:10]:  # Limit to first 10 results
        try:
            name = job.find_element(By.TAG_NAME, "a").text
            link = job.find_element(By.TAG_NAME, "a").get_attribute("href")
            candidates.append({"name": name, "profile_link": link})
        except:
            continue

    driver.quit()
    return candidates
```

---

### ‚úÖ Step 3: Create a View to Trigger the Scraper

üìÑ **File:** `core/views.py`

Add this new import:

```python
from .monster_scraper import fetch_monster_profiles
```

Add a new view function:

```python
@require_http_methods(["GET"])
def scrape_monster_profiles(request):
    keyword = request.GET.get('keyword', 'python developer')
    results = fetch_monster_profiles(keyword)

    return JsonResponse({'profiles': results})
```

---

### ‚úÖ Step 4: Map the URL

üìÑ **File:** `core/urls.py`

```python
from .views import scrape_monster_profiles

urlpatterns += [
    path('scrape/monster/', scrape_monster_profiles, name='scrape_monster'),
]
```

---

### ‚úÖ Step 5: Test in Browser or Postman

Try this URL:

```
http://127.0.0.1:8000/scrape/monster/?keyword=django+developer
```

You will get a JSON response with candidate names and profile links.

---

‚úÖ **Done:** You now have a basic Monster profile scraper integrated with your Django backend.

---
